# PredictorTransformer 模型修改说明

## 问题描述

在使用PredictorTransformer模型进行训练时，出现维度不匹配的错误：
```
RuntimeError: The size of tensor a (100) must match the size of tensor b (50) at non-singleton dimension 2
```

**问题原因：**
- 输入序列长度：100 (sequence_length)
- 输出序列长度应为：50 (output_sequence_length)
- 但模型实际输出：[B, 2, 100] 而不是 [B, 2, 50]

原始模型的输出投影只改变了特征维度（从d_model到output_size），但保持了序列长度不变。

## 修改方案

采用了reshape + 线性投影的方案来改变输出序列长度：

### 1. 添加 `output_sequence_length` 参数

在 `__init__` 方法中添加了新参数：
```python
def __init__(self,
             ...
             sequence_length: int = 100,           # 输入序列长度
             output_sequence_length: int = 50,     # 输出序列长度
             ...)
```

### 2. 修改输出投影层

**原始方案：**
```python
# 只改变特征维度，保持序列长度
self.output_projection = nn.Linear(d_model, output_size)
# 输出: [B, N, output_size] -> [B, output_size, N]
```

**新方案：**
```python
# 先reshape，再通过线性层改变序列长度和特征维度
self.output_projection = nn.Linear(
    sequence_length * d_model,              # 输入: N_in * d_model
    output_sequence_length * output_size    # 输出: N_out * output_size
)
```

### 3. 修改前向传播逻辑

**关键步骤：**

1. **Transformer输出后：** `[B, N_in, d_model]` (N_in=100, d_model=128)

2. **Reshape展平：**
   ```python
   x = x.reshape(batch_size, -1)
   # [B, N_in, d_model] -> [B, N_in * d_model]
   # [B, 100, 128] -> [B, 12800]
   ```

3. **线性投影：**
   ```python
   x = self.output_projection(x)
   # [B, N_in * d_model] -> [B, N_out * output_size]
   # [B, 12800] -> [B, 100]  (因为 N_out=50, output_size=2, 50*2=100)
   ```

4. **Reshape回序列格式：**
   ```python
   x = x.reshape(batch_size, self.output_size, self.output_sequence_length)
   # [B, N_out * output_size] -> [B, output_size, N_out]
   # [B, 100] -> [B, 2, 50]
   ```

## 使用方法

### 模型创建

```python
from models.predictor_model import PredictorTransformer

model = PredictorTransformer(
    input_size=25,
    output_size=2,
    d_model=128,
    nhead=8,
    num_encoder_layers=4,
    dim_feedforward=512,
    dropout=0.1,
    sequence_length=100,           # 输入序列长度
    output_sequence_length=50,     # 输出序列长度
    use_positional_encoding=True,
    center=config.center,
    scale=config.scale
)
```

### 配置文件

确保 `default_config.py` 中设置了正确的参数：
```python
# 输入序列长度（滑动窗口大小）
sequence_length = 100

# 输出序列长度（预测的时间步数）
output_sequence_length = 50
```

### 训练时的维度

- **输入：** `[batch_size, input_size, sequence_length]` = `[B, 25, 100]`
- **标签：** `[batch_size, output_size, output_sequence_length]` = `[B, 2, 50]`
- **输出：** `[batch_size, output_size, output_sequence_length]` = `[B, 2, 50]`

现在输出和标签维度完全匹配！

## 优势

1. **灵活性：** 支持任意的输入/输出序列长度组合
2. **可扩展性：** 通过reshape和线性层，模型可以学习输入到输出的时间映射关系
3. **向后兼容：** 当 `sequence_length == output_sequence_length` 时，行为类似原始模型

## 测试验证

模型已通过以下测试：
```python
# 测试不同的序列长度组合
test_configs = [
    (100, 50),   # 输入100，输出50
    (100, 100),  # 输入100，输出100
    (200, 100),  # 输入200，输出100
    (50, 25)     # 输入50，输出25
]
```

所有配置都能正确生成对应维度的输出。

## 注意事项

1. **参数量变化：** 由于输出投影层变大，模型参数会增加
   - 原始: `d_model * output_size` 参数
   - 新方案: `(sequence_length * d_model) * (output_sequence_length * output_size)` 参数

2. **内存使用：** 在reshape步骤会临时使用更多内存

3. **训练调整：** 
   - 可能需要调整学习率
   - 建议使用梯度裁剪（已在train.py中实现）

## 相关文件

- `predictor_model.py` - 修改后的模型文件
- `default_config.py` - 配置文件（需确保包含output_sequence_length参数）
- `train.py` - 训练脚本（需确保传递output_sequence_length参数）

## 总结

这个修改解决了输出序列长度不匹配的问题，使模型能够灵活地将任意长度的输入序列映射到不同长度的输出序列。通过reshape和线性投影的组合，模型可以学习输入时间序列到输出时间序列的复杂映射关系。