# DataLoader NaNè‡ªåŠ¨ç§»é™¤åŠŸèƒ½æ›´æ–°

## ğŸ¯ é—®é¢˜åˆ†æ

### å‘ç°çš„é—®é¢˜

åœ¨æ•°æ®é›†çš„CSVæ–‡ä»¶æœ«å°¾ç»å¸¸å­˜åœ¨å¤§é‡NaNå€¼ï¼Œå¯¼è‡´ï¼š

1. **è®­ç»ƒæ—¶æ¢¯åº¦åä¼ åè¾“å‡ºNaN**
   - æ¨¡å‹åœ¨åŒ…å«NaNçš„æ•°æ®ä¸Šè®¡ç®—æŸå¤±
   - åå‘ä¼ æ’­äº§ç”ŸNaNæ¢¯åº¦
   - å‚æ•°æ›´æ–°åæ¨¡å‹è¾“å‡ºå˜ä¸ºNaN

2. **è®¡ç®—å½’ä¸€åŒ–å‚æ•°æ—¶å‡ºç°NaN**
   - å‡å€¼è®¡ç®—åŒ…å«NaNï¼Œç»“æœä¸ºNaN
   - æ ‡å‡†å·®åœ¨æœ‰NaNæ—¶è®¡ç®—ä¸å‡†ç¡®
   - å¯¼è‡´æ¨¡å‹å½’ä¸€åŒ–å¤±è´¥

### æ ¹æœ¬åŸå› 

CSVæ–‡ä»¶ç»“æ„ç¤ºä¾‹ï¼š
```
timestamp,foot_imu_r_gyro_x,foot_imu_r_gyro_y,...
0.005,    0.123,            0.456,            ...
0.010,    0.234,            0.567,            ...
...
5.000,    0.345,            0.678,            ...
5.005,    NaN,              NaN,              ...  â† ä»è¿™é‡Œå¼€å§‹éƒ½æ˜¯NaN
5.010,    NaN,              NaN,              ...
...
```

## âœ¨ è§£å†³æ–¹æ¡ˆ

### æ ¸å¿ƒä¿®æ”¹

ä¿®æ”¹äº† `dataset_loaders/dataloader.py`ï¼Œæ·»åŠ äº†**è‡ªåŠ¨NaNæ£€æµ‹å’Œæˆªæ–­**åŠŸèƒ½ï¼š

#### 1. æ–°å¢ `_find_nan_cutoff()` æ–¹æ³•

```python
def _find_nan_cutoff(self, df: pd.DataFrame, columns: List[str]) -> int:
    """
    åœ¨æŒ‡å®šåˆ—ä¸­æŸ¥æ‰¾ç¬¬ä¸€ä¸ªåŒ…å«NaNçš„è¡Œç´¢å¼•
    è¿”å›æˆªæ–­ä½ç½®ï¼Œä¿ç•™å¹²å‡€çš„æ•°æ®
    """
```

**åŠŸèƒ½**ï¼š
- æ‰«ææŒ‡å®šçš„è¾“å…¥åˆ—
- æ‰¾åˆ°ç¬¬ä¸€ä¸ªåŒ…å«NaNçš„è¡Œ
- è¿”å›æˆªæ–­ç´¢å¼•

#### 2. ä¿®æ”¹ `_load_input_data()` æ–¹æ³•

**æ–°å¢åŠŸèƒ½**ï¼š
- åœ¨åŠ è½½CSVåè‡ªåŠ¨æ£€æµ‹NaN
- åœ¨ç¬¬ä¸€ä¸ªNaNè¡Œä¹‹å‰æˆªæ–­æ•°æ®
- è¿›è¡ŒäºŒæ¬¡æ£€æŸ¥ç¡®ä¿æ•°æ®å®Œå…¨å¹²å‡€
- è¿”å›æˆªæ–­é•¿åº¦ä¿¡æ¯

#### 3. ä¿®æ”¹ `_load_label_data()` æ–¹æ³•

**æ–°å¢åŠŸèƒ½**ï¼š
- æ¥å— `cutoff_length` å‚æ•°
- è‡ªåŠ¨æˆªæ–­åˆ°ä¸è¾“å…¥æ•°æ®ç›¸åŒçš„é•¿åº¦
- ç¡®ä¿è¾“å…¥å’Œæ ‡ç­¾é•¿åº¦ä¸€è‡´

#### 4. æ–°å¢ç»Ÿè®¡åŠŸèƒ½

```python
def print_nan_removal_summary(self):
    """æ‰“å°NaNç§»é™¤ç»Ÿè®¡æ‘˜è¦"""
```

æ˜¾ç¤ºï¼š
- å¤„ç†çš„è¯•éªŒæ€»æ•°
- åŒ…å«NaNçš„è¯•éªŒæ•°
- ç§»é™¤çš„æ€»è¡Œæ•°
- å¹³å‡æ¯ä¸ªè¯•éªŒç§»é™¤çš„è¡Œæ•°

### æ–°å¢å‚æ•°

åœ¨ `TcnDataset` ç±»åˆå§‹åŒ–æ—¶æ–°å¢ï¼š

```python
remove_nan: bool = True  # æ˜¯å¦è‡ªåŠ¨ç§»é™¤åŒ…å«NaNçš„è¡Œ
```

- `True`ï¼šå¯ç”¨è‡ªåŠ¨NaNç§»é™¤ï¼ˆ**é»˜è®¤ï¼Œæ¨è**ï¼‰
- `False`ï¼šç¦ç”¨ï¼Œä¿ç•™åŸå§‹æ•°æ®ï¼ˆç”¨äºè°ƒè¯•ï¼‰

## ğŸ“– ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬ç”¨æ³•ï¼ˆæ¨èï¼‰

```python
from dataset_loaders.dataloader import TcnDataset

# åˆ›å»ºæ•°æ®é›†ï¼ˆé»˜è®¤å¯ç”¨NaNç§»é™¤ï¼‰
dataset = TcnDataset(
    data_dir='data/example',
    input_names=input_names,
    label_names=label_names,
    side='r',
    participant_masses=participant_masses,
    device=device,
    mode='train',
    remove_nan=True  # é»˜è®¤å€¼ï¼Œå¯ä»¥çœç•¥
)

# åŠ è½½æ•°æ®ï¼ˆä¼šè‡ªåŠ¨ç§»é™¤NaNï¼‰
input_data, label_data, lengths = dataset[:]

# æ‰“å°ç»Ÿè®¡ä¿¡æ¯
dataset.print_nan_removal_summary()
```

### è¾“å‡ºç¤ºä¾‹

```
åŠ è½½è¯•éªŒæ•°æ®: BT23/walking
  è¾“å…¥æ•°æ®: data/example/train/BT23/walking/BT23_walking_exo.csv, åŸå§‹æ•°æ®å½¢çŠ¶: (5000, 25)
    æ£€æµ‹åˆ°NaN: ä»ç¬¬ 4850 è¡Œå¼€å§‹, å°†ç§»é™¤ 150 è¡Œ
  æˆªæ–­åæ•°æ®å½¢çŠ¶: (4850, 25)
  æ ‡ç­¾æ•°æ®: data/example/train/BT23/walking/BT23_walking_moment_filt.csv, åŸå§‹æ•°æ®å½¢çŠ¶: (5000, 2)
  æ ‡ç­¾æ•°æ®æˆªæ–­åˆ°: (4850, 2)

============================================================
NaNç§»é™¤ç»Ÿè®¡æ‘˜è¦ - TRAIN æ•°æ®é›†
============================================================
å¤„ç†çš„è¯•éªŒæ€»æ•°: 25
åŒ…å«NaNçš„è¯•éªŒæ•°: 18
ç§»é™¤çš„æ•°æ®è¡Œæ€»æ•°: 2450
åŒ…å«NaNçš„è¯•éªŒæ¯”ä¾‹: 72.00%
å¹³å‡æ¯ä¸ªå«NaNè¯•éªŒç§»é™¤çš„è¡Œæ•°: 136.1
============================================================
```

## ğŸ§ª æµ‹è¯•éªŒè¯

### è¿è¡Œæµ‹è¯•è„šæœ¬

```bash
# æµ‹è¯•NaNç§»é™¤åŠŸèƒ½
python test_nan_removal.py --config_path configs.TCN.default_config
```

æµ‹è¯•å†…å®¹ï¼š
1. âœ… å¯¹æ¯”å¯ç”¨/ç¦ç”¨NaNç§»é™¤çš„æ•ˆæœ
2. âœ… æµ‹è¯•è®­ç»ƒé›†åŠ è½½
3. âœ… æµ‹è¯•æµ‹è¯•é›†åŠ è½½
4. âœ… å•ç‹¬æµ‹è¯•å¤šä¸ªtrials
5. âœ… éªŒè¯æ•°æ®å®Œæ•´æ€§

### é¢„æœŸè¾“å‡º

```
å¯¹æ¯”ç»“æœ:
======================================================================
ç¦ç”¨NaNç§»é™¤çš„NaNæ•°é‡: 150
å¯ç”¨NaNç§»é™¤çš„NaNæ•°é‡: 0

âœ“âœ“âœ“ NaNç§»é™¤åŠŸèƒ½å·¥ä½œæ­£å¸¸ï¼
```

## ğŸ”„ å®Œæ•´å·¥ä½œæµç¨‹æ›´æ–°

### æ–°çš„æ¨èæµç¨‹

```bash
# 1. æ£€æŸ¥åŸå§‹æ•°æ®ä¸­çš„NaNåˆ†å¸ƒ
python utils/check_data_nan.py --detailed --export nan_analysis.txt

# 2. æµ‹è¯•NaNç§»é™¤åŠŸèƒ½
python test_nan_removal.py

# 3. è®¡ç®—å½’ä¸€åŒ–å‚æ•°ï¼ˆç°åœ¨ä¼šè‡ªåŠ¨è·³è¿‡NaNï¼‰
python compute_normalization_params.py

# 4. æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„centerå’Œscale

# 5. è¿è¡Œè¯Šæ–­ï¼ˆéªŒè¯ä¸€åˆ‡æ­£å¸¸ï¼‰
python diagnose_nan.py

# 6. å¼€å§‹è®­ç»ƒï¼ˆæ•°æ®å·²ç»å¹²å‡€ï¼‰
python train.py
```

## ğŸ“Š æŠ€æœ¯ç»†èŠ‚

### NaNæ£€æµ‹é€»è¾‘

```python
# 1. æ£€æŸ¥æ¯ä¸€è¡Œæ˜¯å¦åŒ…å«NaN
nan_mask = df[input_names].isna().any(axis=1)

# 2. æ‰¾åˆ°ç¬¬ä¸€ä¸ªåŒ…å«NaNçš„è¡Œ
nan_indices = nan_mask[nan_mask].index.tolist()

# 3. åœ¨è¯¥è¡Œä¹‹å‰æˆªæ–­
if nan_indices:
    cutoff_index = nan_indices[0]
    df = df.iloc[:cutoff_index]
```

### äºŒæ¬¡æ£€æŸ¥æœºåˆ¶

å³ä½¿åœ¨æˆªæ–­åï¼Œä»ç„¶ä¼šè¿›è¡ŒäºŒæ¬¡æ£€æŸ¥ï¼š

```python
# æå–æ•°æ®åå†æ¬¡æ£€æŸ¥
extracted_data = df[input_names].values
if pd.isna(extracted_data).any():
    # è¿›ä¸€æ­¥æ¸…ç†
    nan_rows = pd.isna(extracted_data).any(axis=1)
    clean_data = extracted_data[~nan_rows]
```

è¿™ç¡®ä¿äº†**ç»å¯¹ä¸ä¼šæœ‰NaNè¿›å…¥è®­ç»ƒè¿‡ç¨‹**ã€‚

### é•¿åº¦åŒæ­¥

è¾“å…¥å’Œæ ‡ç­¾æ•°æ®é•¿åº¦è‡ªåŠ¨åŒæ­¥ï¼š

```python
# åŠ è½½è¾“å…¥æ•°æ®å¹¶è·å–æˆªæ–­é•¿åº¦
input_data, cutoff_length = self._load_input_data(input_path, body_mass)

# åŠ è½½æ ‡ç­¾æ•°æ®å¹¶ä½¿ç”¨ç›¸åŒçš„æˆªæ–­é•¿åº¦
label_data = self._load_label_data(label_path, cutoff_length=cutoff_length)
```

## âš™ï¸ é…ç½®é€‰é¡¹

### åœ¨ä»£ç ä¸­é…ç½®

```python
# æ–¹å¼1: å¯ç”¨NaNç§»é™¤ï¼ˆé»˜è®¤ï¼Œæ¨èï¼‰
dataset = TcnDataset(..., remove_nan=True)

# æ–¹å¼2: ç¦ç”¨NaNç§»é™¤ï¼ˆä»…ç”¨äºè°ƒè¯•ï¼‰
dataset = TcnDataset(..., remove_nan=False)
```

### åœ¨é…ç½®æ–‡ä»¶ä¸­é…ç½®ï¼ˆå¯é€‰ï¼‰

å¯ä»¥åœ¨ `configs/TCN/default_config.py` ä¸­æ·»åŠ ï¼š

```python
# æ•°æ®åŠ è½½é…ç½®
remove_nan = True  # æ˜¯å¦è‡ªåŠ¨ç§»é™¤NaNè¡Œ
```

ç„¶ååœ¨åˆ›å»ºæ•°æ®é›†æ—¶ä½¿ç”¨ï¼š

```python
dataset = TcnDataset(..., remove_nan=config.remove_nan)
```

## ğŸ¯ æ•ˆæœéªŒè¯

### éªŒè¯æ¸…å•

- [ ] è¿è¡Œ `python utils/check_data_nan.py` æŸ¥çœ‹åŸå§‹æ•°æ®NaNåˆ†å¸ƒ
- [ ] è¿è¡Œ `python test_nan_removal.py` éªŒè¯ç§»é™¤åŠŸèƒ½
- [ ] è¿è¡Œ `python compute_normalization_params.py` ç¡®è®¤å‚æ•°æ­£å¸¸
- [ ] è¿è¡Œ `python diagnose_nan.py` ç¡®è®¤æ— NaNé—®é¢˜
- [ ] å¼€å§‹è®­ç»ƒï¼Œè§‚å¯Ÿæ˜¯å¦è¿˜æœ‰NaNé”™è¯¯

### æˆåŠŸæ ‡å¿—

âœ… `compute_normalization_params.py` è¾“å‡ºçš„centerå’Œscaleéƒ½æ˜¯æ­£å¸¸æ•°å€¼ï¼ˆæ— NaNï¼‰

âœ… `diagnose_nan.py` æ‰€æœ‰9æ­¥æµ‹è¯•é€šè¿‡

âœ… `train.py` è®­ç»ƒè¿‡ç¨‹ä¸­æ— NaNè­¦å‘Š

âœ… æ¨¡å‹è¾“å‡ºå§‹ç»ˆä¸ºæ­£å¸¸æ•°å€¼

## ğŸ“‹ å…¼å®¹æ€§è¯´æ˜

### å‘åå…¼å®¹

- âœ… é»˜è®¤å¯ç”¨NaNç§»é™¤ï¼Œä¸å½±å“å¹²å‡€æ•°æ®
- âœ… å¯ä»¥é€šè¿‡ `remove_nan=False` æ¢å¤æ—§è¡Œä¸º
- âœ… æ‰€æœ‰ç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹

### æ€§èƒ½å½±å“

- **CPUå¼€é”€**ï¼šæ¯ä¸ªtrialå¢åŠ  < 10msï¼ˆNaNæ£€æµ‹ï¼‰
- **å†…å­˜å¼€é”€**ï¼šæ— é¢å¤–å†…å­˜æ¶ˆè€—ï¼ˆin-placeæˆªæ–­ï¼‰
- **è®­ç»ƒé€Ÿåº¦**ï¼šç§»é™¤NaNååºåˆ—æ›´çŸ­ï¼Œè®­ç»ƒå¯èƒ½æ›´å¿«

## ğŸ” è°ƒè¯•æŠ€å·§

### æŸ¥çœ‹è¯¦ç»†æ—¥å¿—

ä¿®æ”¹åçš„dataloaderä¼šè¾“å‡ºè¯¦ç»†ä¿¡æ¯ï¼š

```python
# åœ¨åŠ è½½æ•°æ®æ—¶ä¼šçœ‹åˆ°
åŠ è½½è¯•éªŒæ•°æ®: BT23/walking
  è¾“å…¥æ•°æ®: ..., åŸå§‹æ•°æ®å½¢çŠ¶: (5000, 25)
    æ£€æµ‹åˆ°NaN: ä»ç¬¬ 4850 è¡Œå¼€å§‹, å°†ç§»é™¤ 150 è¡Œ
  æˆªæ–­åæ•°æ®å½¢çŠ¶: (4850, 25)
```

### å¯¹æ¯”åŸå§‹æ•°æ®

```python
# ç¦ç”¨NaNç§»é™¤æŸ¥çœ‹åŸå§‹æ•°æ®
dataset_raw = TcnDataset(..., remove_nan=False)
input_raw, _, _ = dataset_raw[0]
print(f"åŸå§‹æ•°æ®NaNæ•°é‡: {torch.isnan(input_raw).sum()}")

# å¯ç”¨NaNç§»é™¤æŸ¥çœ‹æ¸…ç†åæ•°æ®
dataset_clean = TcnDataset(..., remove_nan=True)
input_clean, _, _ = dataset_clean[0]
print(f"æ¸…ç†åNaNæ•°é‡: {torch.isnan(input_clean).sum()}")
```

## ğŸ’¡ æœ€ä½³å®è·µ

1. **å§‹ç»ˆå¯ç”¨NaNç§»é™¤**ï¼ˆé™¤éè°ƒè¯•ï¼‰
   ```python
   remove_nan=True  # æ¨è
   ```

2. **æŸ¥çœ‹ç§»é™¤ç»Ÿè®¡**
   ```python
   dataset.print_nan_removal_summary()
   ```

3. **å®šæœŸæ£€æŸ¥åŸå§‹æ•°æ®è´¨é‡**
   ```bash
   python utils/check_data_nan.py --detailed
   ```

4. **ä¿ç•™åŸå§‹æ•°æ®å¤‡ä»½**
   - ä¸è¦ç›´æ¥ä¿®æ”¹CSVæ–‡ä»¶
   - DataLoaderåªåœ¨åŠ è½½æ—¶æˆªæ–­

## â“ å¸¸è§é—®é¢˜

### Q1: ä¼šä¸¢å¤±é‡è¦æ•°æ®å—ï¼Ÿ

**A**: åªç§»é™¤æœ«å°¾çš„NaNè¡Œï¼Œè¿™äº›è¡Œé€šå¸¸æ˜¯ä¼ æ„Ÿå™¨åœæ­¢è®°å½•åçš„æ— æ•ˆæ•°æ®ã€‚å¦‚æœæ‹…å¿ƒï¼Œå¯ä»¥å…ˆç”¨ `check_data_nan.py` æŸ¥çœ‹NaNåˆ†å¸ƒã€‚

### Q2: å¦‚ä½•çŸ¥é“ç§»é™¤äº†å¤šå°‘æ•°æ®ï¼Ÿ

**A**: è°ƒç”¨ `dataset.print_nan_removal_summary()` æŸ¥çœ‹è¯¦ç»†ç»Ÿè®¡ã€‚

### Q3: è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¼šç§»é™¤ä¸åŒæ•°é‡çš„æ•°æ®å—ï¼Ÿ

**A**: æ˜¯çš„ï¼Œæ¯ä¸ªtrialç‹¬ç«‹å¤„ç†ã€‚æ¯ä¸ªæ–‡ä»¶æ ¹æ®è‡ªå·±çš„NaNä½ç½®æˆªæ–­ã€‚

### Q4: å¦‚æœæ•´ä¸ªæ–‡ä»¶éƒ½æ˜¯NaNæ€ä¹ˆåŠï¼Ÿ

**A**: ä¼šæŠ›å‡ºå¼‚å¸¸ï¼Œæç¤ºè¯¥æ–‡ä»¶æ— æœ‰æ•ˆæ•°æ®ã€‚

### Q5: å¯ä»¥ä¿ç•™ä¸€äº›NaNç”¨äºè®­ç»ƒå—ï¼Ÿ

**A**: ä¸æ¨èã€‚NaNä¼šå¯¼è‡´æ¢¯åº¦è®¡ç®—å¤±è´¥ã€‚å¦‚æœéœ€è¦å¤„ç†ç¼ºå¤±å€¼ï¼Œåº”è¯¥åœ¨é¢„å¤„ç†é˜¶æ®µç”¨æ’å€¼ç­‰æ–¹æ³•å¡«å……ã€‚

## ğŸ‰ æ€»ç»“

**ä¿®æ”¹å‰**ï¼š
- âŒ NaNå¯¼è‡´è®­ç»ƒå¤±è´¥
- âŒ å½’ä¸€åŒ–å‚æ•°è®¡ç®—é”™è¯¯
- âŒ éœ€è¦æ‰‹åŠ¨æ¸…ç†æ•°æ®

**ä¿®æ”¹å**ï¼š
- âœ… è‡ªåŠ¨ç§»é™¤NaNè¡Œ
- âœ… æ•°æ®å®Œå…¨å¹²å‡€
- âœ… è®­ç»ƒç¨³å®šè¿›è¡Œ
- âœ… å½’ä¸€åŒ–å‚æ•°æ­£ç¡®

è¿™ä¸ªæ›´æ–°å½»åº•è§£å†³äº†æ•°æ®é›†NaNé—®é¢˜ï¼Œè®©ä½ å¯ä»¥ä¸“æ³¨äºæ¨¡å‹è®­ç»ƒï¼ğŸš€